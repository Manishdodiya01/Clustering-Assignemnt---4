{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75da3030-0c77-4f3a-90c8-2731a3805cf5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q1. Explain the concept of homogeneity and completeness in clustering evaluation. How are they calculated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9c229c4-7c72-4511-89b9-44a1c006c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import homogeneity_completeness_v_measure , homogeneity_score , completeness_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47c8e832-d99d-444f-895e-2e22f7ad60d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7d0861d0f0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "datasets = load_iris()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(datasets.data , columns=datasets.feature_names)\n",
    "df.drop('sepal length (cm)', axis=1 , inplace=True)\n",
    "df.drop('sepal width (cm)' , axis=1 , inplace=True)\n",
    "df.head()\n",
    "\n",
    "plt.scatter(df['petal length (cm)'] , df['petal width (cm)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d922fc62-1b77-4611-91d2-f79666d86660",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = KMeans(n_clusters=2)\n",
    "\n",
    "cluster.fit(df)\n",
    "\n",
    "pre_label = cluster.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78d20e63-6e0e-4f2a-bdb6-501b38f8f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = datasets.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce037801-1a55-4487-be14-9a6080e75621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9490204434010505"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homogeneity_score(pre_label , true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "744b8968-950e-4cab-940b-70f6e0617e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5537492887432671"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_score(pre_label , true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc402f48-f2b6-4ae7-b4d5-bffd91ce925b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q2. What is the V-measure in clustering evaluation? How is it related to homogeneity and completeness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bba6a1f0-859d-42a0-9976-00bcbe9cc99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import v_measure_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd8b134b-21f4-44e8-b38a-71ee356d05ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6994010915914346"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_measure_score(true_labels , pre_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3e6cf1-56af-40d6-a4e2-2310a99b9fde",
   "metadata": {},
   "source": [
    "The V-measure score ranges from 0 to 1, with a higher score indicating better performance. A V-measure score of 1 means that the clustering algorithm has perfectly clustered the data, with both homogeneity and completeness scores of 1.\n",
    "\n",
    "V-measure is a good choice for clustering evaluation because it addresses some of the limitations of homogeneity and completeness. For example, homogeneity and completeness can be high even for a poor clustering solution, if the clusters are small and isolated. V-measure, on the other hand, penalizes clusters that are too small.\n",
    "\n",
    "Relationship between V-measure, homogeneity, and completeness\n",
    "\n",
    "V-measure is related to homogeneity and completeness in the following ways:\n",
    "\n",
    "A high V-measure score requires both high homogeneity and high completeness.\n",
    "A low V-measure score can be caused by either low homogeneity or low completeness.\n",
    "V-measure is more sensitive to completeness than homogeneity.\n",
    "This means that V-measure gives more weight to completeness when calculating the overall score. This is because completeness is more important for many real-world clustering applications. For example, in a customer segmentation task, it is more important to ensure that all customers in a segment are from the same target group, even if some customers from other target groups are also in the segment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbdcf21-f454-4f62-afbf-51399ea72d0c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q3. How is the Silhouette Coefficient used to evaluate the quality of a clustering result? What is the range of its values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5809af4e-4f53-4981-8f3f-7fb79c2b3fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc1ff8f5-2f0e-4944-99f4-308d5974e629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7653904101258123"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(df , pre_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b86a4-6dec-444c-978f-e99790771295",
   "metadata": {},
   "source": [
    "The Silhouette Coefficient is a metric for evaluating the quality of a clustering result. It measures how well each data point is assigned to its cluster, by considering the distance between the data point and other data points in its cluster, as well as the distance between the data point and data points in other clusters.\n",
    "\n",
    "The Silhouette Coefficient is calculated for each data point in the dataset, and the average Silhouette Coefficient is then used to evaluate the overall quality of the clustering. The Silhouette Coefficient can range from -1 to 1:\n",
    "\n",
    "A Silhouette Coefficient of 1 indicates that the data point is very well-assigned to its cluster, and that it is far away from data points in other clusters.\n",
    "A Silhouette Coefficient of 0 indicates that the data point is indifferently assigned to its cluster, and that it is equally close to data points in other clusters.\n",
    "A Silhouette Coefficient of -1 indicates that the data point is very poorly-assigned to its cluster, and that it is closer to data points in other clusters than to data points in its own cluster.\n",
    "A higher Silhouette Coefficient score indicates better clustering results. A Silhouette Coefficient score of 0.5 or higher is generally considered to be good, and a Silhouette Coefficient score of 0.7 or higher is considered to be excellent.\n",
    "\n",
    "How to use the Silhouette Coefficient to evaluate clustering results\n",
    "\n",
    "To use the Silhouette Coefficient to evaluate clustering results, you can follow these steps:\n",
    "\n",
    "Calculate the Silhouette Coefficient for each data point in the dataset.\n",
    "Calculate the average Silhouette Coefficient for the dataset.\n",
    "Interpret the average Silhouette Coefficient score:\n",
    "A score of 0.5 or higher is generally considered to be good.\n",
    "A score of 0.7 or higher is considered to be excellent.\n",
    "A score of less than 0.5 indicates that the clustering results could be improved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bdf36d-aaa5-41d7-94ed-4ad16f50d385",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q4. How is the Davies-Bouldin Index used to evaluate the quality of a clustering result? What is the range of its values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c2919931-33c3-4566-ab5d-79394539c046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26490616966729874"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "davies_bouldin_score(df , pre_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6745bf4-0116-45b1-b8ff-e9c81996b067",
   "metadata": {},
   "source": [
    "The Davies-Bouldin Index (DBI) is a metric for evaluating the quality of a clustering result. It measures the compactness of the clusters and the separation between the clusters. The DBI is calculated as the average ratio of the within-cluster distance to the between-cluster distance for all pairs of clusters.\n",
    "\n",
    "The DBI can range from 0 to infinity. A lower DBI score indicates better clustering results. A DBI score of less than 1 is generally considered to be good, and a DBI score of less than 0.5 is considered to be excellent.\n",
    "\n",
    "How to use the Davies-Bouldin Index to evaluate clustering results\n",
    "\n",
    "To use the Davies-Bouldin Index to evaluate clustering results, you can follow these steps:\n",
    "\n",
    "Calculate the Davies-Bouldin Index for the clustering result.\n",
    "Interpret the Davies-Bouldin Index score:\n",
    "A score of less than 1 is generally considered to be good.\n",
    "A score of less than 0.5 is considered to be excellent.\n",
    "A score of greater than 1 indicates that the clustering results could be improved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17403144-6be5-43b5-9c51-209cb8801115",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q5. Can a clustering result have a high homogeneity but low completeness? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac6f751-4a55-4075-bffc-b58644f6d27c",
   "metadata": {},
   "source": [
    "Yes, a clustering result can have a high homogeneity but low completeness. This means that the clusters are very pure, with most data points in each cluster belonging to the same class, but some classes are not completely captured by any cluster.\n",
    "\n",
    "One example of this is a clustering result of the Iris dataset where the clusters are formed based on the petal length and width. The petal length and width are two highly correlated features, so the clusters formed using these features will be very pure. However, it is possible that some of the Iris flowers will be misclassified, resulting in a low completeness score.\n",
    "\n",
    "Another example is a clustering result of a customer segmentation task where the clusters are formed based on the customer's purchase history. The purchase history data is typically very high-dimensional and complex, so it is possible that the clusters formed using this data will be pure, but not complete.\n",
    "\n",
    "Example:\n",
    "\n",
    "Suppose we have a dataset of images of cats and dogs, and we want to use a clustering algorithm to group the images into two clusters: cats and dogs. The clustering algorithm might find two clusters, but one of the clusters might contain a few dog images. This would result in a high homogeneity score (because most of the images in each cluster are cats or dogs), but a low completeness score (because not all of the dog images are in the dog cluster).\n",
    "\n",
    "How to improve completeness without sacrificing homogeneity\n",
    "\n",
    "There are a few things you can do to improve the completeness of a clustering result without sacrificing homogeneity:\n",
    "\n",
    "Use a clustering algorithm that is designed to produce complete clusters.\n",
    "Use more features in the clustering algorithm. This will help the clustering algorithm to better distinguish between the different classes.\n",
    "Tune the clustering algorithm parameters. For example, you might need to increase the number of clusters or decrease the clustering threshold.\n",
    "Use a post-processing step to merge or split clusters. This can be useful for correcting misclassified data points or for splitting large clusters into smaller, more homogeneous clusters.\n",
    "It is important to note that there is no one-size-fits-all solution for improving the completeness of a clustering result without sacrificing homogeneity. The best approach will depend on the specific dataset and clustering algorithm that you are using.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8fc42c-cef6-41e3-b560-9248ad829156",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q6. How can the V-measure be used to determine the optimal number of clusters in a clustering algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "569a621f-d672-4e03-94f0-43162f6eb6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import v_measure_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "43f686db-04cd-4af4-af1c-24c729c683be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6994010915914346"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_measure_score(true_labels , pre_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe4d8db-22f2-4db8-b2de-06f6ed53db69",
   "metadata": {},
   "source": [
    "\n",
    "The V-measure can be used to determine the optimal number of clusters in a clustering algorithm by calculating the V-measure score for different numbers of clusters and choosing the number of clusters with the highest V-measure score.\n",
    "\n",
    "Here is a step-by-step guide on how to use the V-measure to determine the optimal number of clusters in a clustering algorithm:\n",
    "\n",
    "Choose a range of values for the number of clusters, such as from 2 to 10 clusters.\n",
    "For each number of clusters, train the clustering algorithm on the data and calculate the V-measure score.\n",
    "Choose the number of clusters with the highest V-measure score.\n",
    "It is important to note that the V-measure score can be sensitive to the choice of clustering algorithm and clustering parameters. Therefore, it is important to experiment with different clustering algorithms and parameters to find the best combination for your dataset.\n",
    "\n",
    "Example:\n",
    "\n",
    "Suppose we have a dataset of images of cats and dogs, and we want to use a clustering algorithm to group the images into two clusters: cats and dogs. We can use the V-measure to determine the optimal number of clusters by following these steps:\n",
    "\n",
    "Choose a range of values for the number of clusters, such as from 2 to 10 clusters.\n",
    "For each number of clusters, train a k-means clustering algorithm on the data and calculate the V-measure score.\n",
    "Choose the number of clusters with the highest V-measure score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1c1a26-5094-4f47-becf-2e9a76346016",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q7. What are some advantages and disadvantages of using the Silhouette Coefficient to evaluate a clustering result?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a22d42d-9e36-445b-a883-127cd6ffdaf9",
   "metadata": {},
   "source": [
    "Advantages of using the Silhouette Coefficient to evaluate a clustering result:\n",
    "\n",
    "It is easy to calculate and interpret.\n",
    "It is sensitive to both the compactness of the clusters and the separation between the clusters.\n",
    "It is widely used in practice, so it is easy to compare your results to others.\n",
    "Disadvantages of using the Silhouette Coefficient to evaluate a clustering result:\n",
    "\n",
    "It can be computationally expensive to calculate for large datasets.\n",
    "It is sensitive to outliers.\n",
    "It can be difficult to interpret in cases where the clusters are not well-defined.\n",
    "Overall, the Silhouette Coefficient is a good choice for evaluating the quality of a clustering result, but it is important to be aware of its limitations.\n",
    "\n",
    "Here are some additional tips for using the Silhouette Coefficient effectively:\n",
    "\n",
    "Use the Silhouette Coefficient in conjunction with other clustering evaluation metrics, such as the Davies-Bouldin Index and the V-measure score. This will give you a more complete picture of the quality of the clustering.\n",
    "Consider using a sampling technique to calculate the Silhouette Coefficient for large datasets. This can reduce the computational cost without sacrificing too much accuracy.\n",
    "Be careful when interpreting the Silhouette Coefficient for datasets with outliers. Outliers can artificially lower the Silhouette Coefficient score.\n",
    "If the Silhouette Coefficient score is low, try to identify the reasons why. This may help you to improve the clustering algorithm or to collect better data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534bbfdd-b9fd-4c76-9472-4d9308507cb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q8. What are some limitations of the Davies-Bouldin Index as a clustering evaluation metric? How can they be overcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f53a861-affd-4af6-a88c-bfb53d2208c5",
   "metadata": {},
   "source": [
    "The Davies-Bouldin Index (DBI) is a popular clustering evaluation metric, but it has some limitations. Here are some of the most important limitations:\n",
    "\n",
    "The DBI is sensitive to outliers. Outliers can artificially increase the DBI score, even if the clustering is good.\n",
    "The DBI assumes that the clusters are spherical and have the same size and density. This assumption is often violated in real-world data.\n",
    "The DBI does not take into account the structure or distribution of the data, such as clusters within clusters or non-linear relationships.\n",
    "These limitations can be overcome in the following ways:\n",
    "\n",
    "To reduce the sensitivity of the DBI to outliers, you can use a pre-processing step to remove outliers from the data. You can also use a robust clustering algorithm that is less sensitive to outliers.\n",
    "To address the assumption that the clusters are spherical and have the same size and density, you can use a clustering algorithm that does not make this assumption. For example, you can use a density-based clustering algorithm, such as DBSCAN.\n",
    "To take into account the structure or distribution of the data, you can use a clustering algorithm that is designed to handle these types of data. For example, you can use a hierarchical clustering algorithm, which can identify clusters within clusters.\n",
    "In addition to the above, here are some other tips for using the DBI effectively:\n",
    "\n",
    "Use the DBI in conjunction with other clustering evaluation metrics, such as the Silhouette Coefficient and the V-measure score. This will give you a more complete picture of the quality of the clustering.\n",
    "Be careful when interpreting the DBI score for datasets with outliers. Outliers can artificially increase the DBI score.\n",
    "If the DBI score is high, try to identify the reasons why. This may help you to improve the clustering algorithm or to collect better data.\n",
    "Overall, the DBI is a useful clustering evaluation metric, but it is important to be aware of its limitations and to use it in conjunction with other metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a7749-b73b-48cd-87e3-d0c4ccd7546c",
   "metadata": {},
   "source": [
    "# Q9. What is the relationship between homogeneity, completeness, and the V-measure? Can they have different values for the same clustering result?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980571d4-4493-4c2e-bd4a-22c2a8ee6375",
   "metadata": {},
   "source": [
    "Homogeneity measures how pure the clusters are, meaning how much each cluster contains data points from the same class. A clustering algorithm with high homogeneity will have clusters that are mostly composed of data points from the same class, and very few data points from other classes.\n",
    "\n",
    "Completeness measures how well the clustering algorithm has captured all of the data points in each class. A clustering algorithm with high completeness will have clusters that contain all of the data points from each class.\n",
    "\n",
    "The V-measure is a harmonic mean of homogeneity and completeness. It is a measure of how well the clustering algorithm has grouped the data points into clusters, taking into account both the purity of the clusters and the coverage of the data points.\n",
    "\n",
    "Can homogeneity, completeness, and the V-measure have different values for the same clustering result?\n",
    "\n",
    "Yes, homogeneity, completeness, and the V-measure can have different values for the same clustering result. This is because the three metrics measure different aspects of the clustering result.\n",
    "\n",
    "For example, a clustering result may have high homogeneity and low completeness, meaning that the clusters are very pure, but some of the data points are not in any cluster. Or, a clustering result may have low homogeneity and high completeness, meaning that all of the data points are in a cluster, but the clusters are not very pure.\n",
    "\n",
    "The V-measure takes into account both homogeneity and completeness, so it will be higher for clustering results that have both high homogeneity and high completeness.\n",
    "\n",
    "Example\n",
    "\n",
    "Suppose we have a clustering result of the Iris dataset where the clusters are formed based on the petal length and width. The petal length and width are two highly correlated features, so the clusters formed using these features will be very pure (high homogeneity). However, it is possible that some of the Iris flowers will be misclassified, resulting in a lower completeness score.\n",
    "\n",
    "The V-measure score for this clustering result will be high, because it takes into account both the homogeneity and completeness of the clustering result.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "Homogeneity, completeness, and the V-measure are all important metrics for evaluating the quality of a clustering result. They can have different values for the same clustering result, because they measure different aspects of the clustering result. The V-measure is a harmonic mean of homogeneity and completeness, so it is a good overall measure of the quality of the clustering result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12adafc-0e48-4207-ab5d-05465d75e207",
   "metadata": {},
   "source": [
    "# Q10. How can the Silhouette Coefficient be used to compare the quality of different clustering algorithms on the same dataset? What are some potential issues to watch out for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfeb02d-bb05-42bb-8cb1-3ec2cb2806a7",
   "metadata": {},
   "source": [
    "To compare the quality of different clustering algorithms on the same dataset using the Silhouette Coefficient, you can follow these steps:\n",
    "\n",
    "Train each clustering algorithm on the dataset.\n",
    "Calculate the Silhouette Coefficient score for each clustering algorithm.\n",
    "Compare the Silhouette Coefficient scores of the different clustering algorithms.\n",
    "The clustering algorithm with the highest Silhouette Coefficient score is generally considered to be the best clustering algorithm for the dataset.\n",
    "\n",
    "Potential issues to watch out for:\n",
    "\n",
    "The Silhouette Coefficient can be sensitive to outliers. Outliers can artificially lower the Silhouette Coefficient score for a clustering algorithm.\n",
    "The Silhouette Coefficient can be computationally expensive to calculate for large datasets.\n",
    "The Silhouette Coefficient does not take into account the structure or distribution of the data, such as clusters within clusters or non-linear relationships.\n",
    "To address these issues, you can:\n",
    "\n",
    "Use a pre-processing step to remove outliers from the data.\n",
    "Use a sampling technique to calculate the Silhouette Coefficient for large datasets.\n",
    "Use a clustering algorithm that is designed to handle the structure or distribution of the data.\n",
    "Additional tips:\n",
    "\n",
    "Use the Silhouette Coefficient in conjunction with other clustering evaluation metrics, such as the Davies-Bouldin Index and the V-measure score. This will give you a more complete picture of the quality of the clustering algorithms.\n",
    "Interpret the Silhouette Coefficient scores with caution, especially if the dataset has outliers or a complex structure or distribution.\n",
    "Example:\n",
    "\n",
    "Suppose we have a dataset of images of cats and dogs, and we want to compare the quality of two clustering algorithms: k-means clustering and hierarchical clustering.\n",
    "\n",
    "We can follow the steps above to compare the two algorithms:\n",
    "\n",
    "Train the k-means and hierarchical clustering algorithms on the dataset.\n",
    "Calculate the Silhouette Coefficient score for each clustering algorithm.\n",
    "Compare the Silhouette Coefficient scores of the two clustering algorithms.\n",
    "Suppose the Silhouette Coefficient score for the k-means clustering algorithm is 0.85 and the Silhouette Coefficient score for the hierarchical clustering algorithm is 0.90. This indicates that the hierarchical clustering algorithm is a better clustering algorithm for the dataset than the k-means clustering algorithm.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "The Silhouette Coefficient is a useful metric for comparing the quality of different clustering algorithms on the same dataset. However, it is important to be aware of the potential issues and to use other clustering evaluation metrics in conjunction with the Silhouette Coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423848f3-98ff-4952-9641-3ebd47ddf4e3",
   "metadata": {},
   "source": [
    "# Q11. How does the Davies-Bouldin Index measure the separation and compactness of clusters? What are some assumptions it makes about the data and the clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae96d39-bef8-4d28-9549-318b773e5282",
   "metadata": {},
   "source": [
    "\n",
    "The Davies-Bouldin Index (DBI) measures the separation and compactness of clusters by calculating the ratio of the within-cluster distance to the between-cluster distance for each cluster. The DBI score is then averaged over all clusters to get a single score for the clustering result.\n",
    "\n",
    "Measuring separation\n",
    "\n",
    "The between-cluster distance is measured as the minimum distance between the centroids of any two clusters. This means that the DBI rewards clustering algorithms that produce clusters that are well-separated from each other.\n",
    "\n",
    "Measuring compactness\n",
    "\n",
    "The within-cluster distance is measured as the average distance of each data point to the centroid of its cluster. This means that the DBI penalizes clustering algorithms that produce clusters that are not very compact.\n",
    "\n",
    "Assumptions\n",
    "\n",
    "The DBI makes the following assumptions about the data and the clusters:\n",
    "\n",
    "The data is distributed in a way that makes it possible to form distinct clusters.\n",
    "The clusters are spherical and have the same size and density.\n",
    "The clusters are well-separated from each other.\n",
    "If these assumptions are not met, the DBI score may not be a reliable measure of the quality of the clustering result.\n",
    "\n",
    "Example\n",
    "\n",
    "Suppose we have a dataset of images of cats and dogs, and we want to use the DBI to evaluate the quality of a clustering algorithm. The DBI will calculate the ratio of the within-cluster distance to the between-cluster distance for each cluster. The between-cluster distance will be measured as the minimum distance between the centroids of the cat and dog clusters. The within-cluster distance will be measured as the average distance of each cat image to the centroid of the cat cluster and the average distance of each dog image to the centroid of the dog cluster.\n",
    "\n",
    "If the clustering algorithm produces clusters that are well-separated and compact, the DBI score will be low. If the clustering algorithm produces clusters that are not well-separated or compact, the DBI score will be high.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "The Davies-Bouldin Index is a useful metric for measuring the separation and compactness of clusters. However, it is important to be aware of the assumptions it makes about the data and the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9162742b-b4b8-44d7-a854-c9f6cb2b7801",
   "metadata": {},
   "source": [
    "# Q12. Can the Silhouette Coefficient be used to evaluate hierarchical clustering algorithms? If so, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b9d1e7-e0fc-45fb-9c4a-882b866463ba",
   "metadata": {},
   "source": [
    "Yes, the Silhouette Coefficient can be used to evaluate hierarchical clustering algorithms. However, it is important to note that the Silhouette Coefficient is not specifically designed for hierarchical clustering algorithms, and there are some special considerations that need to be taken into account when using it to evaluate hierarchical clustering results.\n",
    "\n",
    "One of the main challenges of using the Silhouette Coefficient to evaluate hierarchical clustering results is that hierarchical clustering algorithms produce a dendrogram, which is a tree-like structure that represents the relationships between the data points. The Silhouette Coefficient is typically calculated for individual clusters, but it is not clear how to define clusters in a dendrogram.\n",
    "\n",
    "Another challenge is that hierarchical clustering algorithms can produce different clustering results depending on the linkage criterion and cutting height that are used. This means that the Silhouette Coefficient score for a hierarchical clustering result can vary depending on the linkage criterion and cutting height that are chosen.\n",
    "\n",
    "How to use the Silhouette Coefficient to evaluate hierarchical clustering algorithms:\n",
    "\n",
    "One way to use the Silhouette Coefficient to evaluate hierarchical clustering algorithms is to calculate the Silhouette Coefficient score for different cuts of the dendrogram. This can be done by repeatedly cutting the dendrogram at different heights and calculating the Silhouette Coefficient score for each resulting clustering. The Silhouette Coefficient score for the hierarchical clustering algorithm can then be defined as the maximum Silhouette Coefficient score for any cut of the dendrogram.\n",
    "\n",
    "Another way to use the Silhouette Coefficient to evaluate hierarchical clustering algorithms is to use a technique called cluster aggregation. Cluster aggregation is a technique that groups the clusters in a dendrogram into a smaller number of clusters. Once the clusters have been aggregated, the Silhouette Coefficient score can be calculated for the aggregated clusters.\n",
    "\n",
    "It is important to note that the Silhouette Coefficient score for a hierarchical clustering algorithm is only one measure of the quality of the clustering result. Other measures, such as the Davies-Bouldin Index and the V-measure score, can also be used to evaluate hierarchical clustering results.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "The Silhouette Coefficient can be used to evaluate hierarchical clustering algorithms, but it is important to be aware of the challenges and to use other clustering evaluation metrics in conjunction with the Silhouette Coefficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd407225-da5e-4b3f-a92e-89a169e55dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f6b087-6cc2-4b44-92a6-776af57cd192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
